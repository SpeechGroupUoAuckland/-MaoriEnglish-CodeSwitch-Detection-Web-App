{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../../models/biLSTM/normalCase/bilstmSize2.h5'\n",
    "tokenizer_path = '../../models/biLSTM/normalCase/tokenizerBilstmSize2.pickle'\n",
    "padding_length = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 2, 300)            28987200  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 300)            0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              186880    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,174,467\n",
      "Trainable params: 187,267\n",
      "Non-trainable params: 28,987,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## loading trained model. A summary of the model architecture is also presented.\n",
    "with tf.device('/cpu:0'):\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(loaded_model, to_file='bigru_attn_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading tokenizer. \n",
    "with open(tokenizer_path, 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes are [0] for Bilingual; [1] for Maori; [2] for English\n",
    "def detectCodeSwitchingPoint(x: str):\n",
    "    seq = tokenizer.texts_to_sequences([x])\n",
    "    padded = pad_sequences(seq, maxlen=padding_length)\n",
    "    predict = loaded_model.predict(padded)\n",
    "    classes = np.argmax(predict, axis=1)\n",
    "    if classes == 0:\n",
    "        y = x.split()\n",
    "        cw = []\n",
    "        wb = []\n",
    "        for i in y:\n",
    "            if re.search(u'[āēīōūĀĒĪŌŪ]', i):  # adding hand crafted rules\n",
    "                cw.append(1)\n",
    "                wb.append(i)\n",
    "                continue\n",
    "            elif re.search(u'[bBcCdDfFgGjJlLqQsSvVxXyYzZ]', i):\n",
    "                cw.append(2)\n",
    "                wb.append(i)\n",
    "            else:\n",
    "                seq1 = tokenizer.texts_to_sequences([i])\n",
    "                padded1 = pad_sequences(seq1, maxlen=padding_length)\n",
    "                predict1 = loaded_model.predict(padded1)\n",
    "                classw = np.argmax(predict1, axis=1)\n",
    "                classw = int(classw[0])\n",
    "                cw.append(classw)\n",
    "                wb.append(i)\n",
    "\n",
    "            result = []\n",
    "            flag = True\n",
    "            for c in range(len(cw)-1):\n",
    "                if cw[c] == cw[c+1]:\n",
    "                    continue\n",
    "                elif cw[c] != cw[c+1]:\n",
    "                    if flag:\n",
    "                        result.append([c+1])\n",
    "                    else:\n",
    "                        result[-1].append(c+1)\n",
    "                    flag = not flag\n",
    "\n",
    "        return result\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes are [0] for Bilingual; [1] for Maori; [2] for English\n",
    "\n",
    "def sentenceCategory(sentence: str) -> int:\n",
    "  seq = tokenizer.texts_to_sequences([sentence])\n",
    "  padded = pad_sequences(seq, maxlen=padding_length)\n",
    "  predict = loaded_model.predict(padded) \n",
    "  classw = np.argmax(predict,axis=1)\n",
    "  return int(classw[0])\n",
    "\n",
    "def detectCodeSwitchingPointDynamicWindowVersion(x: str, w: int) -> list():\n",
    "    wordsList = x.split()\n",
    "    end = len(wordsList)\n",
    "    if w >= end and end > 2:\n",
    "        w = end - 1\n",
    "    elif end == 1:\n",
    "        w = 1\n",
    "    elif end == 2:\n",
    "        w = 2\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if end < 1:\n",
    "        return []\n",
    "\n",
    "    elif end == 1:\n",
    "        if re.search(u'[āēīōūĀĒĪŌŪ]', x):\n",
    "            return [1]\n",
    "        elif re.search(u'[bBcCdDfFgGjJlLqQsSvVxXyYzZ]', x):\n",
    "            return [2]\n",
    "        else:\n",
    "            return [sentenceCategory(x)]\n",
    "\n",
    "    elif end == 2:\n",
    "        if not re.search(u'[āēīōūĀĒĪŌŪ]', x):\n",
    "            if sentenceCategory(x) == 1 and not re.search(u'[bBcCdDfFgGjJlLqQsSvVxXyYzZ]', x):\n",
    "                return [1, 1]\n",
    "            elif sentenceCategory(x) == 2:\n",
    "                return [2, 2]\n",
    "            else:\n",
    "                if sentenceCategory(wordsList[0]) == 1 and not re.search(u'[bBcCdDfFgGjJlLqQsSvVxXyYzZ]', wordsList[0]):\n",
    "                    return [1, 2]\n",
    "                else:\n",
    "                    return [2, 1]\n",
    "        else:\n",
    "            if re.search(u'[āēīōūĀĒĪŌŪ]', wordsList[0]) and re.search(u'[āēīōūĀĒĪŌŪ]', wordsList[1]):\n",
    "                return [1, 1]\n",
    "            if re.search(u'[āēīōūĀĒĪŌŪ]', wordsList[0]) and not re.search(u'[āēīōūĀĒĪŌŪ]', wordsList[1]):\n",
    "                return [1, 2]\n",
    "            else:\n",
    "                return [2, 1]\n",
    "    \n",
    "    else:\n",
    "        result = []\n",
    "        ptr = 0\n",
    "        while ptr < end:\n",
    "            thisWindow = wordsList[ptr:ptr+w]\n",
    "            if ptr + w > end:\n",
    "                w = end - ptr\n",
    "            else:\n",
    "                pass\n",
    "            if sentenceCategory(\" \".join(thisWindow)) == 1 and not re.search(u'[bBcCdDfFgGjJlLqQsSvVxXyYzZ]', \" \".join(thisWindow)):\n",
    "                result.extend([1 for _ in range(w)])\n",
    "            elif sentenceCategory(\" \".join(thisWindow)) == 2 and not re.search(u'[āēīōūĀĒĪŌŪ]', \" \".join(thisWindow)):\n",
    "                result += [2 for _ in range(w)]\n",
    "            else:\n",
    "                if w >= 4 and w % 2 == 0:\n",
    "                    result += detectCodeSwitchingPointDynamicWindowVersion(\" \".join(thisWindow), w-2)\n",
    "                else:\n",
    "                    result += detectCodeSwitchingPointDynamicWindowVersion(\" \".join(thisWindow), w-1)\n",
    "            ptr += w\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 15:47:09.691206: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n",
      "2022-06-17 15:47:10.404552: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "phrase = \"Ko ngā ērā This is a trial Ko ngā ērā This is a trial Ko ngā ērā This is a trial\"\n",
    "print(detectCodeSwitchingPointDynamicWindowVersion(phrase, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Labels_Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Will the</td>\n",
       "      <td>P,P</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tertiary Education</td>\n",
       "      <td>P,P</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commission be</td>\n",
       "      <td>P,P</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>measuring the</td>\n",
       "      <td>P,P</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>improvement in</td>\n",
       "      <td>P,P</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text label  Labels_Final\n",
       "0            Will the   P,P             2\n",
       "1  Tertiary Education   P,P             2\n",
       "2       Commission be   P,P             2\n",
       "3       measuring the   P,P             2\n",
       "4      improvement in   P,P             2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../small_data.csv\")\n",
    "\n",
    "df.drop(columns=['id', 'number', 'Labels_Final'], inplace=True)\n",
    "\n",
    "newDf = pd.DataFrame(columns=['text', 'label'])\n",
    "\n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "for row in df.itertuples():\n",
    "    text = row.text.split(' ')\n",
    "    label = row.label.split(',')\n",
    "    if len(text) > len(label):\n",
    "        text = text[:len(label)]\n",
    "    elif len(text) < len(label):\n",
    "        label = label[:len(text)]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    for i in range(0, len(text), WINDOW_SIZE):\n",
    "        newDf.loc[len(newDf)] = [' '.join(text[i:i+WINDOW_SIZE]), ','.join(label[i:i+WINDOW_SIZE])]\n",
    "\n",
    "def labelGen(text: str) -> str:\n",
    "    \"\"\"Read labels and generate the final label\"\"\"\n",
    "    if \"P\" in text and \"M\" in text:\n",
    "        return \"B\"  # Bilingual\n",
    "    elif \"P\" in text:\n",
    "        return \"P\"  # English or English + numbers\n",
    "    elif \"M\" in text:\n",
    "        return \"M\"  # Māori or Māori + numbers\n",
    "    elif \"N\" in text:\n",
    "        return \"N\" # Pure numbers\n",
    "    else:\n",
    "        return \"U\"  # Unknown\n",
    "\n",
    "newDf['Labels_Final'] = newDf['label'].apply(labelGen)\n",
    "\n",
    "df = newDf.replace({'Labels_Final': {'P': 2, 'M': 1, 'B':0}})\n",
    "df['Labels_Final'] = df['Labels_Final'].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "------------------------------------------\n",
      "Total sentence label error 0\n",
      " \n",
      "Total number of words 2872\n",
      "Total word label error in bilingual sentences 37\n"
     ]
    }
   ],
   "source": [
    "sentence_label_error = 0\n",
    "word_label_error = 0\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    x = row['text']\n",
    "    l = row['Labels_Final']\n",
    "    lw = row['label']\n",
    "    ly = lw.split(\",\")\n",
    "    ly = [item.replace(\"P\", \"2\") for item in ly]\n",
    "    ly = [item.replace(\"M\", \"1\") for item in ly]\n",
    "\n",
    "    for i, j in zip(detectCodeSwitchingPointDynamicWindowVersion(x, 2), ly):\n",
    "        if i != int(j):\n",
    "            word_label_error += 1\n",
    "            # break\n",
    "        \n",
    "\n",
    "total_words = df['text'].apply(lambda x: len(str(x).split(' '))).sum()\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "print(\"------------------------------------------\")\n",
    "print(\"Total sentence label error\", sentence_label_error)\n",
    "print(\" \")\n",
    "print(\"Total number of words\",  total_words)\n",
    "print(\"Total word label error in bilingual sentences\", word_label_error)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48caaebc5ae0c247be4f972c3642ff874087c1f9cc458b6f1157e23ba1abcd1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
