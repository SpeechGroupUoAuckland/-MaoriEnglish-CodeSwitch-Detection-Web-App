{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../../models/biLSTM/normalCase/bilstm.h5'\n",
    "tokenizer_path = '../../models/biLSTM/normalCase/tokenizerBilstm.pickle'\n",
    "padding_length = 250\n",
    "\n",
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 250, 300)          23180100  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 250, 300)          0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              186880    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,367,367\n",
      "Trainable params: 187,267\n",
      "Non-trainable params: 23,180,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## loading trained model. A summary of the model architecture is also presented.\n",
    "with tf.device('/cpu:0'):\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(loaded_model, to_file='bigru_attn_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading tokenizer. \n",
    "with open(tokenizer_path, 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "['30.87%', '68.22%', '0.91%']\n"
     ]
    }
   ],
   "source": [
    "phrase = \"Ko ngā ērā This is a trial Ko ngā ērā This is a trial Ko ngā ērā This is a trial\"\n",
    "seq = tokenizer.texts_to_sequences([phrase])\n",
    "padded = pad_sequences(seq, maxlen=padding_length)\n",
    "print([f'{r*100:.2f}%' for r in loaded_model.predict(padded)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 13:52:11.961795: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n",
      "2022-06-26 13:52:13.232222: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Bilingual sentence: Ko ngā ērā This is a trial\n",
      "code-switch detected after the word { Ko } and { ngā }\n",
      "code-switch detected after the word { ērā } and { This }\n",
      " \n",
      "Bilingual sentence: The winners will be chosen by their kaitiaki (tribal guardians)\n",
      "code-switch detected after the word { their } and { kaitiaki }\n",
      "code-switch detected after the word { kaitiaki } and { (tribal }\n",
      " \n",
      "Bilingual sentence: Running very late, been here almost 30 mins. Haere mai please Flyer.\n",
      "code-switch detected after the word { mins. } and { Haere }\n",
      "code-switch detected after the word { mai } and { please }\n",
      " \n",
      "Bilingual sentence: Great workshop in Nelson today, thanks to iwi, central + regional gov, community groups, NGOs & industry who took part\n",
      "code-switch detected after the word { to } and { iwi, }\n",
      "code-switch detected after the word { iwi, } and { central }\n"
     ]
    }
   ],
   "source": [
    "# Hybrid-model ***MODEL 2***\n",
    "# classes are [0] for Bilingual; [1] for Maori; [2] for English\n",
    "\n",
    "# A few random samples ### Change these sentences\n",
    "use_samples = ['Ko ngā ērā This is a trial', 'The winners will be chosen by their kaitiaki (tribal guardians)', 'Running very late, been here almost 30 mins. Haere mai please Flyer.',\n",
    "               'Ko ngā ngeru ērā', 'Great workshop in Nelson today, thanks to iwi, central + regional gov, community groups, NGOs & industry who took part', 'good morning']\n",
    "\n",
    "for x in use_samples:\n",
    "    seq = tokenizer.texts_to_sequences([x])\n",
    "    padded = pad_sequences(seq, maxlen=padding_length)\n",
    "    predict = loaded_model.predict(padded)\n",
    "    classes = np.argmax(predict, axis=1)\n",
    "    if classes == 0:\n",
    "        print(\" \")\n",
    "        print(\"Bilingual sentence:\", x)\n",
    "        y = x.split()\n",
    "        cw = []\n",
    "        wb = []\n",
    "        for i in y:\n",
    "            if re.search(u'[āēīōūĀĒĪŌŪ]', i):  # adding hand crafted rules\n",
    "                classw = np.array([1])\n",
    "                cw.append(classw)\n",
    "                wb.append(i)\n",
    "        #    print(wb,\":\",cw)\n",
    "                continue\n",
    "            elif re.search(u'[bBcCdDfFgGjJlLqQsSvVxXyYzZ]', i):\n",
    "                classw = np.array([2])\n",
    "                cw.append(classw)\n",
    "                wb.append(i)\n",
    "            else:\n",
    "                seq1 = tokenizer.texts_to_sequences([i])\n",
    "                padded1 = pad_sequences(seq1, maxlen=padding_length)\n",
    "                predict1 = loaded_model.predict(padded1)\n",
    "                classw = np.argmax(predict1, axis=1)\n",
    "                cw.append(classw)\n",
    "                wb.append(i)\n",
    "        # print(wb,\":\",cw)\n",
    "        # print(wb,\":\",cw)\n",
    "        for c in range(len(cw)-1):\n",
    "            if cw[c] == cw[c+1]:\n",
    "                continue\n",
    "            elif cw[c] != cw[c+1]:\n",
    "                print(\"code-switch detected after the word\",\n",
    "                      \"{\", wb[c], \"} and {\", wb[c+1], \"}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes are [0] for Bilingual; [1] for Maori; [2] for English\n",
    "def detectCodeSwitchingPoint(x: str):\n",
    "    seq = tokenizer.texts_to_sequences([x])\n",
    "    padded = pad_sequences(seq, maxlen=padding_length)\n",
    "    predict = loaded_model.predict(padded)\n",
    "    classes = np.argmax(predict, axis=1)\n",
    "    if classes == 0:\n",
    "        y = x.split()\n",
    "        cw = []\n",
    "        wb = []\n",
    "        for i in y:\n",
    "            if re.search(u'[āēīōūĀĒĪŌŪ]', i):  # adding hand crafted rules\n",
    "                cw.append(1)\n",
    "                wb.append(i)\n",
    "                continue\n",
    "            elif re.search(u'[bBcCdDfFgGjJlLqQsSvVxXyYzZ]', i):\n",
    "                cw.append(2)\n",
    "                wb.append(i)\n",
    "            else:\n",
    "                seq1 = tokenizer.texts_to_sequences([i])\n",
    "                padded1 = pad_sequences(seq1, maxlen=padding_length)\n",
    "                predict1 = loaded_model.predict(padded1)\n",
    "                classw = np.argmax(predict1, axis=1)\n",
    "                classw = int(classw[0])\n",
    "                cw.append(classw)\n",
    "                wb.append(i)\n",
    "\n",
    "            result = []\n",
    "            flag = True\n",
    "            for c in range(len(cw)-1):\n",
    "                if cw[c] == cw[c+1]:\n",
    "                    continue\n",
    "                elif cw[c] != cw[c+1]:\n",
    "                    if flag:\n",
    "                        result.append([c+1])\n",
    "                    else:\n",
    "                        result[-1].append(c+1)\n",
    "                    flag = not flag\n",
    "\n",
    "        return result\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes are [0] for Bilingual; [1] for Maori; [2] for English\n",
    "\n",
    "def sentenceCategory(sentence: str) -> int:\n",
    "  seq = tokenizer.texts_to_sequences([sentence])\n",
    "  padded = pad_sequences(seq, maxlen=padding_length)\n",
    "  predict = loaded_model.predict(padded) \n",
    "  classw = np.argmax(predict,axis=1)\n",
    "  return int(classw[0])\n",
    "\n",
    "def detectCodeSwitchingPointDynamicWindowVersion(x: str, w: int) -> list():\n",
    "    wordsList = x.split()\n",
    "    end = len(wordsList)\n",
    "    if w >= end and end > 2:\n",
    "        w = end - 1\n",
    "    elif end == 1:\n",
    "        w = 1\n",
    "    elif end == 2:\n",
    "        w = 2\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if end < 1:\n",
    "        return []\n",
    "\n",
    "    elif end == 1:\n",
    "        if re.search(u'[āēīōūĀĒĪŌŪ]', x):\n",
    "            return [1]\n",
    "        elif re.search(u'[bBcCdDfFgGjJlLqQsSvVxXyYzZ]', x):\n",
    "            return [2]\n",
    "        else:\n",
    "            return [sentenceCategory(x)]\n",
    "\n",
    "    elif end == 2:\n",
    "        if not re.search(u'[āēīōūĀĒĪŌŪ]', x):\n",
    "            if sentenceCategory(x) == 1 and not re.search(u'[bBcCdDfFgGjJlLqQsSvVxXyYzZ]', x):\n",
    "                return [1, 1]\n",
    "            elif sentenceCategory(x) == 2:\n",
    "                return [2, 2]\n",
    "            else:\n",
    "                if sentenceCategory(wordsList[0]) == 1 and not re.search(u'[bBcCdDfFgGjJlLqQsSvVxXyYzZ]', wordsList[0]):\n",
    "                    return [1, 2]\n",
    "                else:\n",
    "                    return [2, 1]\n",
    "        else:\n",
    "            if re.search(u'[āēīōūĀĒĪŌŪ]', wordsList[0]) and re.search(u'[āēīōūĀĒĪŌŪ]', wordsList[1]):\n",
    "                return [1, 1]\n",
    "            if re.search(u'[āēīōūĀĒĪŌŪ]', wordsList[0]) and not re.search(u'[āēīōūĀĒĪŌŪ]', wordsList[1]):\n",
    "                return [1, 2]\n",
    "            else:\n",
    "                return [2, 1]\n",
    "    \n",
    "    else:\n",
    "        result = []\n",
    "        ptr = 0\n",
    "        while ptr < end:\n",
    "            thisWindow = wordsList[ptr:ptr+w]\n",
    "            if ptr + w > end:\n",
    "                w = end - ptr\n",
    "            else:\n",
    "                pass\n",
    "            if sentenceCategory(\" \".join(thisWindow)) == 1 and not re.search(u'[bBcCdDfFgGjJlLqQsSvVxXyYzZ]', \" \".join(thisWindow)):\n",
    "                result.extend([1 for _ in range(w)])\n",
    "            elif sentenceCategory(\" \".join(thisWindow)) == 2 and not re.search(u'[āēīōūĀĒĪŌŪ]', \" \".join(thisWindow)):\n",
    "                result += [2 for _ in range(w)]\n",
    "            else:\n",
    "                if w >= 4 and w % 2 == 0:\n",
    "                    result += detectCodeSwitchingPointDynamicWindowVersion(\" \".join(thisWindow), w-2)\n",
    "                else:\n",
    "                    result += detectCodeSwitchingPointDynamicWindowVersion(\" \".join(thisWindow), w-1)\n",
    "            ptr += w\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2]\n",
      "[[1, 3], [8, 10], [15, 17]]\n"
     ]
    }
   ],
   "source": [
    "phrase = \"Ko ngā ērā This is a trial Ko ngā ērā This is a trial Ko ngā ērā This is a trial\"\n",
    "print(detectCodeSwitchingPointDynamicWindowVersion(phrase, 5))\n",
    "print(detectCodeSwitchingPoint(phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>number</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Labels_Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H20031118</td>\n",
       "      <td>36</td>\n",
       "      <td>Will the Tertiary Education Commission be meas...</td>\n",
       "      <td>P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,M,P,P,P,P,P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H20031118</td>\n",
       "      <td>54</td>\n",
       "      <td>What progress is being made on Treaty of Waita...</td>\n",
       "      <td>P,P,P,P,P,P,P,P,M,P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H20031118</td>\n",
       "      <td>59</td>\n",
       "      <td>We will also be shortly signing another deed o...</td>\n",
       "      <td>P,P,P,P,P,P,P,P,P,P,P,M,M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H20031118</td>\n",
       "      <td>71</td>\n",
       "      <td>The Office of Treaty Settlements, with Te Puni...</td>\n",
       "      <td>P,P,P,P,P,P,M,M,M,P,P,P,P,P,P,P,P,P,P,P,P,P,P,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H20031118</td>\n",
       "      <td>74</td>\n",
       "      <td>When will the Minister undertake a comprehensi...</td>\n",
       "      <td>P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  number                                               text  \\\n",
       "0  H20031118      36  Will the Tertiary Education Commission be meas...   \n",
       "1  H20031118      54  What progress is being made on Treaty of Waita...   \n",
       "2  H20031118      59  We will also be shortly signing another deed o...   \n",
       "3  H20031118      71  The Office of Treaty Settlements, with Te Puni...   \n",
       "4  H20031118      74  When will the Minister undertake a comprehensi...   \n",
       "\n",
       "                                               label  Labels_Final  \n",
       "0  P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,M,P,P,P,P,P             0  \n",
       "1                                P,P,P,P,P,P,P,P,M,P             0  \n",
       "2                          P,P,P,P,P,P,P,P,P,P,P,M,M             0  \n",
       "3  P,P,P,P,P,P,M,M,M,P,P,P,P,P,P,P,P,P,P,P,P,P,P,...             0  \n",
       "4  P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,P,...             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../small_data.csv\")\n",
    "\n",
    "df = df.replace({'Labels_Final': {'P': 2, 'M': 1, 'B':0}})\n",
    "df['Labels_Final'] = df['Labels_Final'].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "------------------------------------------\n",
      "Window size:  2\n",
      "Total sentence label error 0\n",
      "Total number of words 2872\n",
      "Total word label error in bilingual sentences 33\n",
      " \n",
      "------------------------------------------\n",
      "Window size:  3\n",
      "Total sentence label error 0\n",
      "Total number of words 2872\n",
      "Total word label error in bilingual sentences 36\n",
      " \n",
      "------------------------------------------\n",
      "Window size:  4\n",
      "Total sentence label error 0\n",
      "Total number of words 2872\n",
      "Total word label error in bilingual sentences 30\n",
      " \n",
      "------------------------------------------\n",
      "Window size:  5\n",
      "Total sentence label error 0\n",
      "Total number of words 2872\n",
      "Total word label error in bilingual sentences 38\n",
      " \n",
      "------------------------------------------\n",
      "Window size:  6\n",
      "Total sentence label error 0\n",
      "Total number of words 2872\n",
      "Total word label error in bilingual sentences 31\n",
      " \n",
      "------------------------------------------\n",
      "Window size:  7\n",
      "Total sentence label error 0\n",
      "Total number of words 2872\n",
      "Total word label error in bilingual sentences 31\n",
      " \n",
      "------------------------------------------\n",
      "Window size:  8\n",
      "Total sentence label error 0\n",
      "Total number of words 2872\n",
      "Total word label error in bilingual sentences 32\n",
      " \n",
      "------------------------------------------\n",
      "Window size:  9\n",
      "Total sentence label error 0\n",
      "Total number of words 2872\n",
      "Total word label error in bilingual sentences 28\n"
     ]
    }
   ],
   "source": [
    "for window in range(2, 10):\n",
    "    sentence_label_error = 0\n",
    "    word_label_error = 0\n",
    "\n",
    "    for ind, row in df.iterrows():\n",
    "        x = row['text']\n",
    "        l = row['Labels_Final']\n",
    "        lw = row['label']\n",
    "        ly = lw.split(\",\")\n",
    "        ly = [item.replace(\"P\", \"2\") for item in ly]\n",
    "        ly = [item.replace(\"M\", \"1\") for item in ly]\n",
    "\n",
    "        for i, j in zip(detectCodeSwitchingPointDynamicWindowVersion(x, window), ly):\n",
    "            if i != int(j):\n",
    "                word_label_error += 1\n",
    "                # break\n",
    "            \n",
    "\n",
    "    total_words = df['text'].apply(lambda x: len(str(x).split(' '))).sum()\n",
    "\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"Window size: \", window)\n",
    "    print(\"Total sentence label error\", sentence_label_error)\n",
    "    print(\"Total number of words\",  total_words)\n",
    "    print(\"Total word label error in bilingual sentences\", word_label_error)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48caaebc5ae0c247be4f972c3642ff874087c1f9cc458b6f1157e23ba1abcd1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
